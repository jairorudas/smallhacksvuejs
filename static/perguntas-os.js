module.exports = [ 
    {
      title: "Sobre a classificação de sistemas operacionais (SO), descreva os possı́veis tipos de SO quanto a:",
			respostas: '',
			url: '',
			enuns:{
				a: 'Número de usuários Um sistema operacional é dito monousuário se somente um único usuário puder acessar o sistema de uma vez, isto é, um outro usuário somente poderá usar o sistema quando o usuário atual deixar de usar o sistema. Já em um sistema multiusuário, vários usuários podem acessar simultaneamente o sistema opera cional, isto é, um usuário não precisa esperar um outro usuário deixar de usar o sistema para usálo. ',
				b: 'Número de programas Um sistema monoprogramado permite que somente um programa seja executado por vez no sistema, isto é, um novo pro grama somente poderá ser executado após o programa atualmente em execução terminar. Já em um sistema multiprogramado, pode mos ter vários programas em execução no sistema, sendo que um programa não precisará esperar o término do outro para começar a ser executado (os programas poderão ou não executar simultanea mente, dependendo do número de processadores do computador).'
			},
			questoes:[{
				item: {
					enunciado: 'Número de usuários:',
					res: 'Um sistema operacional é dito monousuário se somente um único usuário puder acessar o sistema de uma vez, isto é, um outro usuário somente poderá usar o sistema quando o usuário atual deixar de usar o sistema. Já em um sistema multiusuário, vários usuários podem acessar simultaneamente o sistema opera cional, isto é, um usuário não precisa esperar um outro usuário deixar de usar o sistema para usálo. ',
					url: ''
				}
			},
			{
				item: {
					enunciado: 'Número de programas:',
					res: 'Um sistema monoprogramado permite que somente um programa seja executado por vez no sistema, isto é, um novo pro grama somente poderá ser executado após o programa atualmente em execução terminar. Já em um sistema multiprogramado, pode mos ter vários programas em execução no sistema, sendo que um programa não precisará esperar o término do outro para começar a ser executado (os programas poderão ou não executar simultanea mente, dependendo do número de processadores do computador).',
					url: ''
				}
			}]
		},
	{
      	title: "Qual é o objetivo das chamadas ao sistema operacional? Dê uma descrição de como estas funcionam, evidenciando qual o papel das bi bliotecas.",
		respostas: "As chamadas ao sistema operacional objetivam fornecer uma interface entre os processos executando no modo usuário e as diversas funções oferecidas pelo sistema operacional. Quando um processo deseja fazer uma chamada ao sistema, este de verá fazer uma chamada a uma das funções da biblioteca que tratam dos detalhes de executar esta chamada. O motivo de usarmos a biblio teca é porque além de esta fornecer funções que facilitam ou estendem a funcionalidade de cada chamada ao sistema, esta também facilita a execução da própria chamada, pois o modo de implementar uma chamada depende do hardware em que o sistema operacional está exe 2cutando. Antes de chamar a função da biblioteca, o processo deverá colocar na pilha os parâmetros requeridos por esta função. Depois de o processo chamar a função, esta determinará qual chamada ao sistema deverá ser executada, colocará os parâmetros desta chamada no local em que o sistema operacional espera que estes estejam (um identifica dor para a chamada, e os parâmetros da chamada), e executará uma instrução TRAP (cuja implementação dependerá do hardware) para passar o controle ao sistema operacional (comutando o processador do modo usuário para o modo supervisor). Depois de o sistema operacional ser chamado, este determinará, através do identificador, o endereço da chamada que foi executada (usando este identificador como um ı́ndice em uma tabela com os endereços de todas as chamadas), e saltará para este endereço. O código para o qual o sistema saltou, chamado de o tratador da chamada, executará então as tarefas necessárias à execução desta chamada ao sistema, bloqueando o processo que fez a chamada à biblioteca se for necessário esperar a ocorrência de algum evento ex terno. Caso este tratador termine sem bloquear o processo, o sistema operacional executará uma instrução de retorno de uma TRAP, que fará o processador retornar ao modo usuário, e continuar a execução a partir da instrução imediatamente posterior à instrução TRAP execu tada. A função da biblioteca então devolverá o controle ao processo, que deverá remover os parâmetros da pilha para finalizar corretamente a chamada à função da biblioteca.",
	},
	{
      	title: "Qual é a principal vantagem do modelo de micronúcleo conside rando múltiplos processadores",
		respostas: "No modelo de micronúcleo a maior parte das funcionalidades do sistema são implementadas no modo usuário, por processos servi dores. O micronúcleo, que executa no modo supervisor, somente trata do acesso direto aos dispositivos de E/S (que não pode ser feito no modo usuário), e dos detalhes necessários à troca de mensagens en tre os processos do sistema, pois os serviços do sistema operacional, como as chamadas ao sistema, devem ser solicitados através do envio de mensagens aos servidores que executam estes serviços. A vanta gem é exatamente o fato de usarmos mensagens para que o sistema execute tarefas para os processos (chamados de clientes), pois nada impede que os servidores estejam em processadores ou computadores 3diferentes, sendo que no primeiro caso as mensagens podem ser troca das por uma rede especializada que conecta todos os processadores, e no segundo caso por uma rede de computadores comum interligando os computadores."
	},
	{
      	title: "Descreva os estados de um processo e as ações levadas a cabo em cada uma das possı́veis transições entre estes estados como descrito na figura a seguir:",
		url: './static/img/os/ap1/processos.png',
			respostas: "Um processo pode estar em três estados: executando, quando este está sendo executado pelo processador; pronto, quando este pro cesso está esperando para ser executado no processador (pois algum outro processo está em execução no processador); e bloqueado, quando o processo não pode executar no processador até a ocorrência de algum evento externo. A Transição 1, do estado executando para o bloque ado, ocorre quando um processo em execução descobre que somente poderá continuar a executar após a ocorrência de um certo evento ex terno à sua execução. A Transição 2, do estado executando para o pronto, ocorre quando o escalonador determinou que o processo atual mente em execução já executou por muito tempo no processador. A Transição 3, do estado pronto para o executando, ocorre quando o es calonador determinou que é a vez deste processo, que estava esperando pelo uso do processador, de executar no processador por algum tempo. Finalmente, a Transição 4, do estado bloqueado para o pronto, significa que o evento externo pelo qual este processo estava esperando ocorreu, e com isso, o processo poderá agora ser escolhido pelo escalonador para ser futuramente executado pelo processador.",
	},
	{
    	title: "Suponha que dois processos, A e B, se comunicam usando a pa lavra da memória R, sendo que R é usada para transferir dados do processo A para o processo B, como descrito pela figura a seguir:",
		url: './static/img/os/ap1/ex0.png',
		respostas: '',
		enuns: {
			a: 'O acesso irrestrito à palavra R pelos processos A e B gera condições de corrida. Descreva estas condições As condições de corrida ocorrerão quando o processo A tentar escrever na palavra R quase ao mesmo tempo em que o processo B tentar ler um valor desta palavra. Temos dois casos: no primeiro, A pode escrever novamente na posição R antes de B ler o valor escrito anteriormente por A, o que fará com que este valor seja perdido; e no segundo, B tentará ler um valor da posição R antes que A coloque um novo valor nesta posição, o que fará com que B leia novamente o mesmo valor',
			b: 'Explique quais são os semáforos necessários para a correta implementação da comunicação entre os processos A e B. Dê os valores iniciais desses semáforos para o caso em que a palavra R está inicialmente ocupada por um dado e preencha as lacunas nos códigos abaixo indicando os nomes dos semáforos apropriados Precisamos de dois semáforos binários, dado disponivel e dado ja lido. O semáforo dado disponivel irá controlar o acesso do processo B à palavra R, somente permitindo o acesso quando R possuir um novo valor, colocado por A, a ser lido por B. Como inicialmente a palavra R está ocupada por um dado, o valor ini cial do semáforo dado disponivel será 1. O semáforo dado ja lido irá controlar o acesso do processo A à palavra R, somente per mitindo o acesso após B ler o valor atual de R. Como R está inicialmente ocupada, o valor inicial do semáforo dado ja lido de verá ser 0. Para que a comunicação dos processos seja correta e sincronizada, o processo A deverá executar a operação P so bre dado ja lido antes de escrever um valor em R, e executar a operação V sobre dado disponivel logo após colocar um novo va lor em R. Por sua vez, o processo B deverá executar a operação P sobre dado disponivel antes de ler um valor de R, e deverá execu tar a operação V sobre dado ja lido logo após ler um valor de R. A seguir damos o código obtido ao preencher as lacunas de acordo com o que foi descrito anteriormente'
		},
		questoes:[{
			item: {
				enunciado: 'O acesso irrestrito à palavra R pelos processos A e B gera condições de corrida. Descreva estas condições:',
				res: 'RESP =>: As condições de corrida ocorrerão quando o processo A tentar escrever na palavra R quase ao mesmo tempo em que o processo B tentar ler um valor desta palavra. Temos dois casos: no primeiro, A pode escrever novamente na posição R antes de B ler o valor escrito anteriormente por A, o que fará com que este valor seja perdido; e no segundo, B tentará ler um valor da posição R antes que A coloque um novo valor nesta posição, o que fará com que B leia novamente o mesmo valor.',
				url: ''
			}
		},
		{
			item: {
				enunciado: 'Explique quais são os semáforos necessários para a correta implementação da comunicação entre os processos A e B. Dê os valores iniciais desses semáforos para o caso em que a palavra R está inicialmente ocupada por um dado e preencha as lacunas nos códigos abaixo indicando os nomes dos semáforos apropriados:',
				res: 'Precisamos de dois semáforos binários, dado disponivel e dado ja lido. O semáforo dado disponivel irá controlar o acesso do processo B à palavra R, somente permitindo o acesso quando R possuir um novo valor, colocado por A, a ser lido por B. Como inicialmente a palavra R está ocupada por um dado, o valor ini cial do semáforo dado disponivel será 1. O semáforo dado ja lido irá controlar o acesso do processo A à palavra R, somente per mitindo o acesso após B ler o valor atual de R. Como R está inicialmente ocupada, o valor inicial do semáforo dado ja lido de verá ser 0. Para que a comunicação dos processos seja correta e sincronizada, o processo A deverá executar a operação P so bre dado ja lido antes de escrever um valor em R, e executar a operação V sobre dado disponivel logo após colocar um novo va lor em R. Por sua vez, o processo B deverá executar a operação P sobre dado disponivel antes de ler um valor de R, e deverá execu tar a operação V sobre dado ja lido logo após ler um valor de R. A seguir damos o código obtido ao preencher as lacunas de acordo com o que foi descrito anteriormente.',
				url: ''
			}
		}]
	},
	{
    	title: "Suponha que os processos A, B, C e D estão atualmente em execução no sistema, como na figura a seguir, onde são dados, para cada processo, o seu tempo total de execução e a sua prioridade. Quanto tempo será necessário para que cada processo termine a sua execução, se:",
		url: './static/img/os/ap1/ex1.png',
		respostas: '',
			enuns: {
				a: 'Usarmos o algoritmo de escalonamento por round robin, com um quantum igual a uma unidade de tempo. Na execução usando o algoritmo por round robin, cada um dos processos executará em seqüência, um após o outro, até o término do quantum, ou da sua execução. Supondo que os proces sos estão na fila na ordem dada na figura, ou seja, na ordem A, B, C e D, teremos a seguinte seqüência de execução: A, B, C, D, A, B, C, D, A, B, C, D, A, B, C, B e C. Como cada quantum equilave a uma unidade de tempo, então A terminará a sua execução após 13 unidades de tempo, B terminará a sua execução após 16 uni dades de tempo, C terminará a sua execução após 17 unidades de tempo, e D terminará a sua execução após 12 unidades de tempo.',
				b: 'Usarmos o algoritmo de escalonamento por prioridades, com redução de prioridades, supondo que as prioridades são sempre re duzidas de 1, dentro de uma unidade de tempo? Como vimos na Aula 6 que o processo de maior prioridade executa até que a sua prioridade seja menor do que a do processo com a segunda maior prioridade, podemos ter as seguintes ordens de execução (para cada processo damos, entre parênteses, a prio ridade que este processo possui ao ser executado) '
			},
			questoes:[{
				item: {
					enunciado: 'Usarmos o algoritmo de escalonamento por round robin, com um quantum igual a uma unidade de tempo.',
					res: 'RESP =>: Na execução usando o algoritmo por round robin, cada um dos processos executará em seqüência, um após o outro, até o término do quantum, ou da sua execução. Supondo que os proces sos estão na fila na ordem dada na figura, ou seja, na ordem A, B, C e D, teremos a seguinte seqüência de execução: A, B, C, D, A, B, C, D, A, B, C, D, A, B, C, B e C. Como cada quantum equilave a uma unidade de tempo, então A terminará a sua execução após 13 unidades de tempo, B terminará a sua execução após 16 uni dades de tempo, C terminará a sua execução após 17 unidades de tempo, e D terminará a sua execução após 12 unidades de tempo. Como vimos na Aula 6 que o processo de maior prioridade executa até que a sua prioridade seja menor do que a do processo com a segunda maior prioridade, podemos ter as seguintes ordens de execução (para cada processo damos, entre parênteses, a prio ridade que este processo possui ao ser executado)',
					url: ''
				}
			},
			{
				item: {
					enunciado: 'Usarmos o algoritmo de escalonamento por prioridades, com redução de prioridades, supondo que as prioridades são sempre re duzidas de 1, dentro de uma unidade de tempo?',
					res: 'Como vimos na Aula 6 que o processo de maior prioridade executa até que a sua prioridade seja menor do que a do processo com a segunda maior prioridade, podemos ter as seguintes ordens de execução (para cada processo damos, entre parênteses, a prio ridade que este processo possui ao ser executado):',
					url: './static/img/os/ap1/ex2.png'
				}
			}]
	},
	{
      	title: "Por que a multiprogramação é importante para as últimas gerações de computadores?",
		respostas: "Com o passar das gerações, a velocidade de processamento dos computadores se tornou cada vez maior. A velocidade dos dispositi vos fı́sicos também aumentou, mas muito mais lentamente do que a velocidade de processamento. Com isso, o tempo de ociosidade do pro cessador quando o processo em execução fazia operações de E/S ficou, com o passar das gerações, cada vez maior, pois cada processo era exe cutado até terminar, sem interrupções. Além disso, existia uma grande demora para se obter os resultados dos processos. Para evitar esses problemas, o conceito de multiprogramação, que permite que mais de um processo esteja em execução no sistema através da divisão do tempo de processamento entre os processos, foi definido a partir da terceira geração.",
	},
	{
    	title: "Descreva as seguintes hierarquias que podem ocorrer em um sis tema operacional:",
		url: '',
		respostas: '',
			enuns: {
				a: 'Árvore de processos. Como vimos na Aula 2, um processo pode criar, durante a sua execução, outros processos. Uma árvore de processos é cri ada quando um processo, chamado de pai, cria um outro processo, chamado de filho, que por sua vez pode criar outros processos. Nesta árvore, cada vértice representa um processo diferente, sendo que a raiz é um processo que foi criado pelo sistema operacional (na verdade todos os processos em execução no sistema formam uma única árvore), e uma aresta de um processo em um nı́vel para um outro no próximo nı́vel significa que este último foi criado pelo primeiro.',
				b: 'Hierarquia de diretórios. Quando estudamos o conceito de arquivos na Aula 2, vi mos que um diretório é um arquivo especial que permite agrupar arquivos relacionados. Um diretório é composto por diversas en tradas, sendo que cada uma delas está associada a um arquivo do sistema que pode ser um outro diretório. Como este diretório também pode possuir entradas associadas a outros diretórios, uma hierarquia de diretórios pode então ser formada. Nesta hierar quia, que também define uma árvore, cada vértice representa um arquivo diferente, sendo que a raiz é o único diretório (chamado de diretório raiz) não associado a uma entrada de um outro di retório. Já uma aresta entre um diretório de um nı́vel para um arquivo no próximo nı́vel significa que o último está associado a uma entrada do primeiro.'
			},
			questoes:[{
				item: {
					enunciado: 'Árvore de processos.',
					res: 'Como vimos na Aula 2, um processo pode criar, durante a sua execução, outros processos. Uma árvore de processos é cri ada quando um processo, chamado de pai, cria um outro processo, chamado de filho, que por sua vez pode criar outros processos. Nesta árvore, cada vértice representa um processo diferente, sendo que a raiz é um processo que foi criado pelo sistema operacional (na verdade todos os processos em execução no sistema formam uma única árvore), e uma aresta de um processo em um nı́vel para um outro no próximo nı́vel significa que este último foi criado pelo primeiro.',
					url: ''
				}
			},
			{
				item: {
					enunciado: 'Hierarquia de diretórios.',
					res: 'Quando estudamos o conceito de arquivos na Aula 2, vi mos que um diretório é um arquivo especial que permite agrupar arquivos relacionados. Um diretório é composto por diversas en tradas, sendo que cada uma delas está associada a um arquivo do sistema que pode ser um outro diretório. Como este diretório também pode possuir entradas associadas a outros diretórios, uma hierarquia de diretórios pode então ser formada. Nesta hierar quia, que também define uma árvore, cada vértice representa um arquivo diferente, sendo que a raiz é o único diretório (chamado de diretório raiz) não associado a uma entrada de um outro di retório. Já uma aresta entre um diretório de um nı́vel para um arquivo no próximo nı́vel significa que o último está associado a uma entrada do primeiro.',
					url: ''
				}
			}]
	},
	{
      	title: "O conceito de máquina virtual permite que vários sistemas ope racionais sejam executados na mesma máquina. Como isso é feito?",
		respostas: "Como vimos na Aula 3, uma máquina virtual é uma cópia exata do hardware do computador, tão complexa de ser usada quanto ele. Para permitir que vários sistemas operacionais executem na mesma máquina, uma máquina virtual é definida para cada um dos sistemas, dando a cada sistema a ilusão de que ele está usando exclusivamente a máquina real. Agora, quando um dos sistemas operacionais acessar o “hardware” da sua máquina virtual, este acesso será interceptado por um programa, em execução na máquina real, responsável pelo geren ciamento das máquinas virtuais, e será mapeado para um acesso real ao hardware. Com isso, vários sistemas operacionais poderão executar simultaneamente na mesma máquina, sem interferirem uns com os ou tros.",
	},
	{
    	title: "Suponha que um processo A executa uma seqüência de operações, sendo que cada operação pode ser uma dentre as duas possı́veis definida pela palavra de memória R. De tempos em tempos, o processo A verifica a palavra R para determinar se deve continuar executando a operação atual, ou se deve passar a executar a outra operação. Supo nha que dois processos, B e C, controlem, através da palavra R, qual operação A deverá executar. Responda:",
		url: '',
		respostas: '',
			enuns: {
				a: 'Temos condições de corrida. Quais são elas A existência de condições de corrida está intimamente ligada ao tipo de computação que está sendo realizada pelos processos envolvidos. Por exemplo, quando discutimos o assunto na Aula 5, havia uma condição de corrida entre os processos aces sando a lista de arquivos a serem impressos porque querı́amos ga rantir que todos os arquivos submetidos fossem de fato impressos. No caso da presente questão, a afirmação de que “temos condições de corrida” obriganos, antes de dar uma resposta, a fazer alguma hipótese sobre o funcionamento do processo A e sobre como B e C interferem nesse funcionamento. É possı́vel fazer hipóteses va riadas, mas ilustraremos a resposta para apenas uma: a hipótese de que A tem que ler todos os valores escritos por B ou C. Feita essa hipótese, a condição de corrida presente na situação descrita ocorre entre o par de processos B, C e o processo A. Especifica mente, dependendo de como se intercalem as escritas de B ou C com as leituras de A, valores escritos poderão jamais ser lidos por A.',
				b: 'quais são os semáforos necessários para evitar as condições de corrida? Justifique a sua resposta Como vimos no item anterior, as condições de corrida dependem de uma hipótese sobre o funcionamento do processo A e de como B e C interferem neste funcionamento. A seguir va mos mostrar uma solução que resolve a condição de corrida para a hipótese ilustrada no item anterior. Neste caso, precisaremos de um semáforo binário dado ja lido para controlar a alteração da palavra R, de tal modo que o valor de R somente possa ser alte rado após A ler este valor. O valor inicial deste semáforo deverá ser 0, pois como A já está em execução, R deverá ter o valor da operação inicial a ser executada. Para garantir que A possa ler o valor de R antes de B ou C alterálo novamente, B e C deverão executar a operação P sobre dado ja lido imediatamente antes de alterar o valor de R, e A deverá executar a operação V sobre dado ja lido imediatamente após ler o valor atual de R.'
			},
			questoes:[{
				item: {
					enunciado: 'Temos condições de corrida. Quais são elas?',
					res: 'A existência de condições de corrida está intimamente ligada ao tipo de computação que está sendo realizada pelos processos envolvidos. Por exemplo, quando discutimos o assunto na Aula 5, havia uma condição de corrida entre os processos aces sando a lista de arquivos a serem impressos porque querı́amos ga rantir que todos os arquivos submetidos fossem de fato impressos. No caso da presente questão, a afirmação de que “temos condições de corrida” obriganos, antes de dar uma resposta, a fazer alguma hipótese sobre o funcionamento do processo A e sobre como B e C interferem nesse funcionamento. É possı́vel fazer hipóteses va riadas, mas ilustraremos a resposta para apenas uma: a hipótese de que A tem que ler todos os valores escritos por B ou C. Feita essa hipótese, a condição de corrida presente na situação descrita ocorre entre o par de processos B, C e o processo A. Especifica mente, dependendo de como se intercalem as escritas de B ou C com as leituras de A, valores escritos poderão jamais ser lidos por A.',
					url: ''
				}
			},
			{
				item: {
					enunciado: 'quais são os semáforos necessários para evitar as condições de corrida? Justifique a sua resposta.',
					res: 'Como vimos no item anterior, as condições de corrida dependem de uma hipótese sobre o funcionamento do processo A e de como B e C interferem neste funcionamento. A seguir va mos mostrar uma solução que resolve a condição de corrida para a hipótese ilustrada no item anterior. Neste caso, precisaremos de um semáforo binário dado ja lido para controlar a alteração da palavra R, de tal modo que o valor de R somente possa ser alte rado após A ler este valor. O valor inicial deste semáforo deverá ser 0, pois como A já está em execução, R deverá ter o valor da operação inicial a ser executada. Para garantir que A possa ler o valor de R antes de B ou C alterálo novamente, B e C deverão executar a operação P sobre dado ja lido imediatamente antes de alterar o valor de R, e A deverá executar a operação V sobre dado ja lido imediatamente após ler o valor atual de R.',
					url: ''
				}
			}]
	},
	{
      	title: "Qual é a principal desvantagem que temos ao usarmos um sistema de processamento em lote? Qual conceito foi desenvolvido para tentar evitar esta desvantagem?",
		respostas: "A principal desvantagem de um sistema de processamento em lote é a de o processador ser alocado a um programa até que ele termine a sua execução. Neste sistema, se o programa executar uma operação de E/S, o processador ficará ocioso até esta operação terminar. Se vários programas pudessem compartilhar o processador, quando um deles executasse uma operação de E/S, ele poderia ser bloqueado até a operação terminar, e um outro programa poderia executar no proces sador. Logo, o processador somente ficaria ocioso se nenhum programa no sistema pudesse ser executado (isto é, se todos os programas esti vessem bloqueados). O conceito criado para evitar a ociosidade do processador é o da mul tiprogramação, que permite a vários programas compartilharem o pro cessador e, com isso, evita a ociosidade do processador quando um programa em execução executa uma operação de E/S.",
	},
	{
      	title: "Como podemos acessar um sistema de arquivos diferente daquele em que reside o sistema operacional? Justifique a sua resposta.",
		respostas: "Para podermos acessar os arquivos de um sistema de arquivos diferente daquele em que reside o sistema operacional, devemos usar o conceito da montagem de um sistema de arquivos. Inicialmente, deve mos escolher um ponto de montagem, um diretório na hierarquia do sistema de arquivos com o sistema operacional, a partir do qual serão acessados os arquivos do sistema de arquivos a ser montado. Depois disso, executamos uma chamada ao sistema operacional para montar o sistema de arquivos desejado, usando o diretório escolhido como o ponto de montagem. Agora, os arquivos do sistema de arquivos montado po derão ser acessados como se fossem arquivos do sistema de arquivos com o sistema operacional, a partir do diretório escolhido como o ponto de montagem.",
	},
	{
      	title: "Suponha que um processo executou uma chamada ao sistema operacional. Qual seria a diferença essencial entre uma chamada feita em um sistema em camadas daquela feita em um sistema clienteservidor? Justifique a sua resposta.",
		respostas: "Em um sistema baseado em camadas, o núcleo do sistema operacional é o responsável por executar as chamadas ao sistema operacional. Logo, sempre que um processo fizer uma chamada ao sis tema operacional, uma instrução TRAP será executada para alternar o modo de execução do processador do modo usuário, em que os pro cessos são executados, para o modo supervisor, em que o núcleo do sistema executa. Já em um sistema clienteservidor, as chamadas ao sistema operacional são executadas através do envio de uma mensagem pelo processo que faz a chamada (o cliente) a um processo responsável por executar esta chamada (o servidor) . Ambos os processos executam no modo usuário e, com isso, não é necessária a execução de uma ins trução TRAP. Note que o núcleo do sistema (chamado de micronúcleo) somente trata da troca de mensagens entre os processos executando no modo usuário, e do acesso aos dispositivos fı́sicos através de mensagens especiais enviadas pelos processos responsáveis pelo gerenciamento dos dispositivos.",
	},
	{
      	title: "Descreva o que é um modelo de processos, enfatizando como o processador é compartilhado por todos os processos do sistema, e as funções da tabela de processos e da troca de contexto.",
		respostas: "No modelo de processos, os processos em execução no sistema operacional são organizados como um conjunto de processos seqüenciais. Em geral, o próprio sistema operacional é dividido em processos que são também considerados pelo modelo. Neste modelo, cada pro cesso é associado a um processador virtual, que possui o mesmo estado e os mesmos registradores do processador real do computador, incluindo o contador de programa, que aponta para a próxima instrução a ser executada do processo. O estado e os registradores de cada proces sador virtual são armazenados (junto com outros dados necessários à execução do processo) na entrada do processo, associado ao processador virtual, em uma tabela chamada de tabela de processos. Cada processo 3em execução no sistema possui uma entrada nesta tabela. Para permitir que o processador seja compartilhado por todos os processos, de tem pos em tempos, ou quando o processo em execução faz uma operação de E/S, o escalonador do sistema escolhe um novo processo para exe cutar no processador. Para alternar o processador entre os processos e garantir a correta execução dos processos do sistema, o escalonador deverá executar uma troca de contexto, descrita a seguir. O escalona dor primeiramente suspende o processo em execução, e salva o estado e os valores dos registradores do processador (além de outros dados necessários à execução do processo) na entrada da tabela de processos associada ao processo suspenso. Depois disso, o escalonador copia o estado e os valores dos registradores do processo escolhido para execu tar, da sua entrada na tabela de processos (junto com os outros dados necessários à execução do processo), para o estado e os registradores do processador e, em seguida, coloca o processo escolhido para executar no processador.",
	},
	{
    	title: "Suponha que um conjunto de processos estejam cooperando entre si para executar uma tafera. Cada um dos processos acessa freqüentemente uma variável compartilhada R para obter um identificador. Este identificador deve ser único. Para garantir isso, cada processo lê o valor de R para obter o identificador, depois incrementa o valor obtido em 1 unidade, e depois armazena o novo valor em R. A tafera será execu tada corretamente somente se garantirmos que cada processo sempre obtenha um identificador único.",
		url: '',
		respostas: '',
			enuns: {
				a: 'Se permitirmos o acesso irrestriro a R, não poderemos garantir que a tarefa será executada corretamente, pois teremos condições de corrida. Quais são elas Somente uma condição de corrida ocorrerá, devido ao fato de cada processo primeiramente ler o valor do identificador de R, para depois armazenar o valor do próximo identificador em R. Como as operações de ler e de atualizar o valor de R não são atômicas, um processo pode ler o valor de R e, antes de ele salvar o novo valor em R, um ou mais processos podem ler este mesmo valor de R. Com isso, dois ou mais processos poderão obter o 4mesmo identificador, e a tarefa não será mais corretamente exe cutada.',
				b: 'Um aluno de Sistemas Operacionais propôs a seguinte solução para evitar as condições de corrida: usar um semáforo de contagem S R , inicializado com o número de processos do conjunto. Cada processo, imediatamente antes de ler o valor de R, deve exe cutar a operação P sobre S R e, imediatamente após armazenar o novo valor em R, executar a operação V sobre S R . A solução proposta pelo aluno está correta A solução proposta pelo aluno não está correta. O pro blema não está no uso das operações P e V , que foram correta mente posicionadas no código, mas sim no fato de a proposta usar um semáforo de contagem. Como queremos garantir o acesso ex clusivo a R, S R deverá ser um semáforo binário, para garantir a exclusão mútua. O semáforo deverá ser inicializado com o valor 1, antes de executarmos os processos cooperativos, pois inicialmente R não estará sendo acessado pelos processos.'
			},
			questoes:[
				{
					item: {
						enunciado: 'Se permitirmos o acesso irrestriro a R, não poderemos garantir que a tarefa será executada corretamente, pois teremos condições de corrida. Quais são elas?',
						res: 'Somente uma condição de corrida ocorrerá, devido ao fato de cada processo primeiramente ler o valor do identificador de R, para depois armazenar o valor do próximo identificador em R. Como as operações de ler e de atualizar o valor de R não são atômicas, um processo pode ler o valor de R e, antes de ele salvar o novo valor em R, um ou mais processos podem ler este mesmo valor de R. Com isso, dois ou mais processos poderão obter o mesmo identificador, e a tarefa não será mais corretamente exe cutada.',
						url: ''
					}
				},
				{
					item: {
						enunciado: 'Um aluno de Sistemas Operacionais propôs a seguinte solução para evitar as condições de corrida: usar um semáforo de contagem S R , inicializado com o número de processos do conjunto. Cada processo, imediatamente antes de ler o valor de R, deve exe cutar a operação P sobre S R e, imediatamente após armazenar o novo valor em R, executar a operação V sobre S R . A solução proposta pelo aluno está correta?',
						res: 'A solução proposta pelo aluno não está correta. O problema não está no uso das operações P e V , que foram corretamente posicionadas no código, mas sim no fato de a proposta usar um semáforo de contagem. Como queremos garantir o acesso ex clusivo a R, S R deverá ser um semáforo binário, para garantir a exclusão mútua. O semáforo deverá ser inicializado com o valor 1, antes de executarmos os processos cooperativos, pois inicialmente R não estará sendo acessado pelos processos.',
						url: ''
					}
				}
		]
	},
	{
		title: "Descreva como multiplexar (i) por tempo e (ii) por espaço um dado recurso do computador, destacando em quais casos cada um destes é aplicado.",
		respostas: "A multiplexação dos recursos por tempo é usada pelo sistema operacional para gerenciar os recursos que devem ser usados, de modo exclusivo, por um dado processo (ou programa) durante um dado in- tervalo de tempo. Já a multiplexação dos recursos por espaço é usada pelo sistema operacional para gerenciar os recursos que podem ser com- partilhados por mais de um processo (ou programa) ao mesmo tempo, sendo que somente uma parte do recurso (e não todo o recurso) é usada por cada processo. Por exemplo, o processador do computador (se não for um processador multicore) pode somente executar um processo de cada vez por um dado intervalo de tempo e, por isso, precisa ser um recurso multiplexado por tempo. Já a memória principal do computa- dor precisa ser um recurso multiplexado por espaço, pois ela é dividida entre os diversos processos em execução no computador.",
	},
	{
		title: "Discuta a relação existente entre os seguintes elementos do sistema operacional: processos, arquivos e diretórios e chamadas ao sistema operacional.",
		respostas: "A relação que existe entre os processos e os arquivos e diretórios é a de que os dados usados pelos processos (como, por exemplo, os arquivos de configuração) são, em geral, lidos de arquivos. Além disso, as saı́das com os resultados das computações dos processos também são, em geral, salvas em arquivos. Também, o próprio código do processo, assim como o de outros processos, é armazenado em um arquivo. Os processos podem usar os diretórios para organizar os arquivos de dados que eles usam, ou para organizar as saı́das geradas por sua computação. Agora, para poder criar os arquivos e os diretórios e, para poder e ler e salvar dados nestes arquivos, os processos devem usar as chamadas ao sistema operacional que tratam do gerenciamento do sistema de ar 2quivos. Um processo também pode criar um novo processo através de uma chamada ao sistema operacional que lê o arquivo com o código do processo e que depois cria este processo e o coloca no estado pronto. Um processo não acessa diretamente os arquivos e os diretórios por dois motivos. Primeiro, porque o processo desconhece como os arquivos e os diretórios são salvos no disco (isso dependerá do tipo do sistema de arquivos). Segundo, porque o acesso direto à versão abstrata do disco, disponibilizada pelo sistema operacional, é somente permitido aos processos que compõem o sistema operacional. Em relação a exe cutar diretamente os processos, além do processo desconhecer como os arquivos são salvos no disco e como o código é armazenado em um arquivo, tem o fato de que somente o sistema operacional poder criar novos processos.",
	},
	{
		title: "O grande problema do sistema monolı́tico é a falta de estruturação do seu núcleo. Descreva sucintamente como os modelos baseados em anéis e em micronúcleo estruturam o núcleo do sistema operacional.",
		respostas: "Nos modelos baseados em anéis, assim como ocorre nos modelos baseados em camadas, o núcleo do sistema operacional é dividido em uma hierarquia em camadas, chamadas de anéis, sendo que cada uma delas trata do gerenciamento de alguma parte do hardware. Um anel oferece, aos anéis superiores a ele na hierarquia, uma versão abs trata e mais fácil de usar da parte do hardware que ele gerencia. Com isso, um anel fornece uma interface de acesso que independe da parte do hardware que ele gerencia. Além disso, cada anel somente pode aces sar a versão abstrata do hardware fornecida pelos anéis inferiores, não podendo acessar diretamente a parte do hardware gerenciada por um destes anéis. Já quando usamos um modelo baseado em micronúcleo, todas as funções do sistema são implementadas no modo usuário por processos servidores. Estes processos gerenciam os recursos do hard ware e implementam os diversos serviços oferecidos pelas chamadas ao sistema operacional nos outros modelos. O micronúcleo, que executa no modo supervisor, somente trata da troca de mensagens entre os diversos processos (dos usuários ou do sistema) executando no modo usuário, e do envio de comandos às controladoras dos dispositivos fı́sicos. Estes comandos são passados ao micronúcleo através de mensagens especiais 3enviadas pelos processos servidores que gerenciam estes dispositivos.",
	},
	{
		title: "A multiprogramação permite que vários processos executem realmente em parelelo no computador, isto é, os processos são todos executados simultaneamente?",
		respostas: "Depende. A multiprogramação permite que vários processos compartilhem os processadores do computador, fazendo com que os processos executem alternadamente, isto é, concorram por estes processadores, por um certo intervalo de tempo. Se o número de processadores for maior ou igual do que o de processos no estado pronto, então teremos o que chamamos de um paralelismo real. Neste caso, todos os processos prontos estarão executando paralelamente no computador, um em cada processador diferente. Porém, se o número de processadores for menor, então o número de processos paralelos não será igual ao número processos prontos, e sim, ao de processadores, e os processos alternarão as suas execuções nestes processadores. Neste último caso o paralelismo é aparente (pseudoparalelismo), pois temos a impressão de que todos os processos estão em execução paralela, por causa do pequeno tempo em que um processo executa em um dos processadores antes de cedêlo a um outro processo.",
	},
	{
		title: "Suponha que temos uma pilha com n posições, compartilhada por um conjunto de processos. Esta pilha possui duas operações: empilha, para inserir um elemento no topo da pilha, e desempilha, para remover o elemento do topo da pilha. Como estas operações devem ser implemen- tadas, usando semáforos, para garantir a exclusão mútua ao acessar a pilha e a correta sincronização dos processos?",
		respostas: "Vamos precisar de dois semáforos de contagem, cheio e vazio, e de um semáforo binário, acesso. O semáforo cheio irá bloquear um processo que deseja inserir um elemento no topo da pilha quando ela estiver cheia, ou seja, se possuir n elementos. Já o semáforo vazio irá bloquear um processo que deseja remover o elemento do topo da pi- lha caso ela esteja vazia, isto é, sem nenhum elemento. Finalmente, o semáforo acesso será usado para garantir o acesso exclusivo à pilha. Como não sabemos quantos elementos temos inicialmente na pilha, va- mos supor que a pilha possui a elementos, 0 ≤ a ≤ n. Então, os valores iniciais dos semáforos cheio e vazio serão de, respectivamente, n − a e a. Já o valor inicial do semáforo acesso será de 1, pois inicialmente nenhum processo está usando a pilha. A seguir damos os códigos das funções Empilha(elemento) e Desempilha(elemento), sendo que mos- tramos as posições corretas onde as operações sobre os semáforos devem ser usadas. A função Empilha(elemento) implementa a operação em- pilha, e insere o elemento dado por elemento no topo da pilha. Já a função Desempilha(elemento) implementa a operação desempilha, que remove o elemento do topo da pilha, colocando-o em elemento. Finalmente, a função InsereT opo(elemento) insere elemento no topo da pilha e a função RemoveT opo() remove e retorna o elemento no topo da pilha.",
	},
	{
		title: "Suponha que três processos A, B, e C acabaram de ser iniciados e são os únicos processos em execução no sistema. Suponha ainda que A executa por 2 quanta, B por 1 quantum e C por 3 quanta. Se usarmos o algoritmo de escalonamento por round-robin, qual seria a seqüência de execução dos processos no processador, se A foi o primeiro processo escolhido pelo escalonador e C foi o segundo?",
		respostas: "Como A executa por 2 quanta, B por 1 quantum e C por 3 quanta, então A, B e C serão escolhidos para executar pelo escalonador por, respectivamente, 2, 1 e 3 vezes. Agora, como as duas primeiras escolhas do escalonador foram, respectivamente, A e C, então a ordem de execução será a seguinte: A, C, B, A, C e C.",
	},
	{
		title: "Quais foram as principais inovações introduzidas em cada uma das quatro gerações de computadores?",
		respostas: "A grande inovação introduzida pela primeira geração foi a de que agora o computador poderia executar cálculos matemáticos, que antes eram feitos manualmente por pessoas. Isso era feito através do uso exclusivo do computador pelo programador, que manipulava direta- mente os componentes do hardware. Já na segunda geração, a principal inovação foi a introdução do primeiro sistema operacional, o sistema de gerenciamento em lote. Neste sistema, os usuários submetiam os pro- gramas para execução, que posteriormente eram organizados em lotes pelo operador. Mais tarde, os lotes eram executados no computador pelo sistema operacional, e depois os resultados dos programas eram coletados pelo operador para serem impressos e disponibilizados aos usuários. A principal inovação da terceira geração foi a introdução do conceito de multiprogramação. Este conceito não somente permitiu que diversos programas fossem executados concorrentemente no computa- dor, como também permitiu que o processador deixasse de ficar ocioso quando o programa em execução fazia operações de E/S. Finalmente, a principal inovação da quarta geração foi o surgimento dos computa- dores pessoais, o que permitiu a indivı́duos possuı́rem os seus próprios computadores. Isso não somente causou o resurgimento dos sistemas operacionais monousuários, como também permitiu o surgimento das redes de computadores o que, em conseqüência, causou a criação dos sistemas operacionais de rede e distribuı́dos.",
	},
	{
		title: "Com que finalidade foi criado o conceito de arquivos especiais? Quantos deles existem, e quais são as principais diferenças entre eles?",
		respostas: "Os arquivos especiais foram criados com o objetivo de facilitar o acesso às versões abstratas dos dispositivos fı́sicos do computador criadas pelo sistema operacional, como parte da sua função de prover uma máquina estendida mais fácil de ser usada do que a máquina real. -Existem dois tipos de arquivos especiais, os de bloco e os de caractere. A primeira diferença é no uso destes arquivos. Os arquivos especiais de bloco são usados pelos dispositivos abstratos que são compostos por um conjunto de blocos que podem ser acessados aleatoriamente, como as versões abstratas dos discos fı́sicos do computador. Já os arquivos especiais de caractere são usados por dispositivos abstratos que podem ser modelados por um fluxo de caracteres, como as versões abstratas das impressoras do computador. A outra diferença é a de que podemos acessar qualquer posição de um arquivo especial de bloco, enquanto que em um arquivo especial de caractere, devemos acessar um fluxo contı́nuo de caracteres sempre a partir da última posição acessada do arquivo.",
	},
	{
		title: "Qual é a função exercida pelo monitor de máquina virtual?",
		respostas: "O monitor de máquina virtual é o responsável pela criação e pelo gerenciamento das máquinas virtuais. As máquinas virtuais cria- das pelo monitor são cópias idênticas da máquina real, ou seja, não são criadas máquinas estendidas, com dispositivos abstratos mais fáceis de serem usados. Como parte do gerenciamento, o monitor de máquina virtual provê o compartilhamento da máquina real entre as diversas máquinas virtuais, o que permite que cada uma delas possa usar os recursos (como o processador) da máquina real. Para fazer isso, o mo- nitor intercepta cada acesso ao hardware em cada máquina virtual, para mapeá-lo para um acesso ao hardware da máquina real. Isso será feito de modo transparente ao programa (em geral um sistema operaci- onal) executado sobre a máquina virtual, pois o resultado deste acesso será passado para este programa como se tivesse vindo diretamente do hardware da máquina real.",
	},
	{
		title: "Discuta o papel das interrupções no escalonamento dos processos pelo sistema operacional.",
		respostas: "As interrupções são essenciais quando o sistema operacional usa um algoritmo de escalonamento preemptivo, isto é, um algoritmo que alterna o uso do processador entre os processos, ao invés de alocar o processador a um processo até ele terminar a sua execução. O algo- ritmo de escalonamento usa as interrupções para suspender o processo em execução, e para desbloquear um processo caso a interrupção in- dique que o evento externo (por exemplo, o término de uma operação de E/S) que o processo estava esperando ocorreu. No primeiro caso, quando a interrupção ocorre, o escalonador pode permitir que o pro- cesso continue a executar, ou pode escolher um outro processo para executar no processador. Finalmente, no segundo caso, o escalonador pode alocar imediatamente o processador ao processo desbloqueado se ele precisar tratar imediatamente do resultado gerado pelo evento, ou pode colocar o processo no estado pronto se o resultado do evento pode ser tratado mais tarde.",
	},
	{
		title: "Suponha que temos uma região de memória R compartilhada por vários processos. Como podemos usar os semáforos para garantir o acesso exclusivo a esta região de memória R?",
		respostas: "Para garantir que cada processo acesse exclusivamente a região de memória R, precisaremos usar um semáforo binário acesso. Como inicialmente nenhum processo estará executando e acessando a região de memória R, o valor inicial de acesso será de 1. Agora, quando um processo desejar acessar a região de memória R, ele deverá executar a operação P sobre acesso imediatamente antes de acessar R, e deverá executar a operação V sobre acesso imediatamente após acessar R.",
	},
	{
		title: "Descreva os algoritmos de escalonamento (i) por round robin; (ii) por prioridades; e (iii) o do trabalho mais curto primeiro.",
		respostas: '',
			enuns: {
				a: 'No algoritmo de escalonamento por round robin, os processos no estado pronto executam alternadamente no processador por um quan- tum, cuja duração é definida pelo sistema operacional e é unico para todos os processos. Depois de executar por um quantum, um processo somente executará novamente no processador após todos os outros pro- cessos no estado pronto terem executado no processador por um quan- tum.',
				b: 'No algoritmo de escalonamento por prioridades, uma prioridade é atribuı́da a cada um dos processos do sistema. Quando o escalonador for chamado para escolher um processo para ser executado, o processo no estado pronto com a maior prioridade será o escolhido. Este pro- cesso será executado até que a sua prioridade não seja mais maior ou igual do que as outras prioridades. Naturalmente, se o processo preci- sar ser bloqueado antes de o escalonador decidir que um outro processo deve ser executado, ele será bloqueado, e o próximo processo no estado pronto com a maior prioridade será o escolhido para ser executado no processador.',
				c: 'No algoritmo do trabalho mais curto primeiro, o único dos algoritmos não-preemptivo, os processos no estado pronto são primeiramente orde- nados, em ordem crescente, de acordo com os tempos que eles precisam executar no processador. Logo, precisamos saber a priori o tempo de execução de cada processo do sistema no processador. Depois da or- denação, cada um destes processos, na ordem definida anteriormente, é executado exclusivamente no processador até terminar a sua execução, após o processo anterior, se existir, ter executado exclusivamente no processador.'
			},
			questoes:[
				{
					item: {
						enunciado: 'No algoritmo de escalonamento',
						res: 'No algoritmo de escalonamento por round robin, os processos no estado pronto executam alternadamente no processador por um quan- tum, cuja duração é definida pelo sistema operacional e é unico para todos os processos. Depois de executar por um quantum, um processo somente executará novamente no processador após todos os outros pro- cessos no estado pronto terem executado no processador por um quan- tum.',
						url: ''
					}
				},
				{
					item: {
						enunciado: 'No algoritmo de escalonamento por prioridades,',
						res: 'Uma prioridade é atribuı́da a cada um dos processos do sistema. Quando o escalonador for chamado para escolher um processo para ser executado, o processo no estado pronto com a maior prioridade será o escolhido. Este pro- cesso será executado até que a sua prioridade não seja mais maior ou igual do que as outras prioridades. Naturalmente, se o processo preci- sar ser bloqueado antes de o escalonador decidir que um outro processo deve ser executado, ele será bloqueado, e o próximo processo no estado pronto com a maior prioridade será o escolhido para ser executado no processador.',
						url: ''
					}
				},
				{
					item: {
						enunciado: 'No algoritmo do trabalho mais curto primeiro',
						res: 'O único dos algoritmos não-preemptivo, os processos no estado pronto são primeiramente orde- nados, em ordem crescente, de acordo com os tempos que eles precisam executar no processador. Logo, precisamos saber a priori o tempo de execução de cada processo do sistema no processador. Depois da or- denação, cada um destes processos, na ordem definida anteriormente, é executado exclusivamente no processador até terminar a sua execução, após o processo anterior, se existir, ter executado exclusivamente no processador.',
						url: ''
					}
				}
		]
	},
	{
		title: "Para os usuários do computador, qual é a diferença essencial entre os sistemas de lote e os sistemas de compartilhamento de tempo?",
		respostas: "A diferença é que em um sistema de lote, os usuários subme- tem os seus programas para execução no computador. Posteriormente, os programas de diversos usuários são organizados em lotes pelos ope- radores, e são colocados, por estes, para executarem no computador. Após as execuções, os resultados dos programas são coletados pelos ope- radores (por exemplo, eles são impressos), e são disponibilizados aos usuários que originalmente submeteram os programas. Em essência, não existe nenhuma interação do usuário com o computador, somente do usuário com os operadores. Já em um sistema de compartilhamento de tempo, os usuários acessam o computador a partir de terminais, portanto interagindo diretamente com o computador. Além disso, os próprios usuários, que têm a ilusão de estarem usando exclusivamente o computador, colocam os programas para executarem no computador e coletam os resultados destas execuções após o término dos programas.",
	},
	{
		title: "Qual é a principal vantagem de uma hierarquia de diretórios em relação a uma abordagem alternativa em que todos os arquivos do sis- tema operacional sejam armazenados em um mesmo diretório?",
		respostas: "Quando todos os arquivos são armazenados em um mesmo di- retório, além de não poderem existir dois ou mais arquivos com mesmo nome, também não se podem organizar os arquivos, em categorias, de acordo com os seus conteúdos. Agora, se o sistema operacional possui uma hierarquia de diretórios, podem existir dois ou mais arquivos com o mesmo nome, desde que sejam armazenados em diretórios diferentes. Além disso, a própria hierarquia, em que os diretórios de um nı́vel, diferente do primeiro, são subdiretórios do diretório do nı́vel imedia- tamente anterior (o diretório do primeiro nı́vel, o diretório raiz, não é subdiretório de nenhum diretório), permite naturalmente organizar os arquivos de acordo com os seus conteúdos. Por exemplo, em uma hi- erarquia de diretórios, cada usuário do sistema operacional pode ter o seu próprio diretório, e pode criar, por exemplo, um subdiretório para figuras, um para textos e um para músicas. Se existisse somente um diretório, não somente todos os arquivos de todos os usuários deveriam ser armazenados nele, como um usuário não poderia criar subdiretórios e dividir os seus arquivos de acordo com os seus conteúdos.",
	},
	{
		title: "A multiprogramação precisa ser visı́vel ao usuário do computador?",
		respostas: "Não, a multiprogramação não precisa ser visı́vel ao usuário do computador. Se o sistema operacional executar no hardware e imple- mentar a multiprogramação, então ela será visı́vel ao usuário do compu- tador. Isso ocorrerá porque ele saberá que cada programa é executado por um processo diferente do sistema operacional, e que estes processos compartilham o(s) processador(es) do hardware. Agora, se o sistema operacional executar em uma máquina virtual, o usuário do computa- dor não saberá que o processador do hardware está sendo multiprogra- mado, pois terá a impressão de que o sistema operacional está execu- tando exclusivamente no computador. Quem será o responsável por multiprogramar o processador, neste caso, será o monitor de máquina virtual, que irá mapear, de tempos em tempos, o processador de cada máquina virtual no processador do hardware. Note que o usuário sa- berá, porém, da multiprogramação do processador da máquina virtual, se o sistema operacional for multiprogramado.",
	},
	{
		title: "Como o modelo de processos facilita o entendimento e a imple- mentação da multiprogramação?",
		respostas: "No modelo de processos, o sistema operacional é visto como um conjunto de processos sequenciais. Para cada processo, as informações necessárias à sua execução, incluindo os registradores do processador, são salvas no seu contexto quando ele deixa de executar no proces- sador, e são restauradas quando ele voltar a executar no processador. Logo, podemos imaginar que cada um destes processos está executando em um processador virtual cujo conteúdo dos registradores são exata- mente aqueles que foram salvos no contexto do processo. Portanto, o conceito facilitará o entendimento da multiprogramação, pois ela ocor- rerá naturalmente quando alternarmos o uso do processador do hardware entre estes processadores virtuais. O conceito também facilitará a implementação da multiprogramação, pois bastará salvarmos os re- gistradores do processador no contexto do processo quando ele deixar de executar no processador, e restaurar os registradores do contexto imediatamente antes de o processo voltar a executar no processador.",
	},
	{
		title: "Descreva como os semáforos são implementados no sistema ope- racional, destacando o modo de funcionamento das operações P e V.",
		respostas: "Cada semáforo do sistema operacional é composto por um valor inteiro e por uma fila que armazena as informações sobre cada processo bloqueado por causa deste semáforo. As operações P e V são imple- mentadas no núcleo do sistema operacional de modo atômico, isto é, os códigos que as implementam são executados do inı́cio até o fim sem interrupções, para garantir a exclusão mútua ao acessar o valor e a fila. A ação executada pela operação P dependerá do valor associado ao semáforo. Se este valor for maior do que 0, a operação simplesmente o decrementará em uma unidade. Porém, se este valor for igual a 0, o processo que executou a operação será bloqueado, e as informações que o identificam serão inseridas na fila do semáforo. A ação executada pela operação V também dependerá do valor do semáforo. Se o valor for maior do que 0, ele será incrementado em uma unidade se o semáforo for de contagem (pois o valor de um semáforo binário somente pode ser 0 ou 1). Se o valor for 0 e a fila não estiver vazia, um dos processos cujas informações estão na fila será escolhido aleatoriamente, as suas informações serão removidas da fila, e ele será desbloqueado e colocado no estado pronto, para depois poder ser escolhido pelo escalonador. Finalmente, se o valor for 0 e a fila estiver vazia, ele também será in- crementado em uma unidade.",
	},
	{
		title: "O algoritmo de escalonamento por round robin precisa ser preemp- tivo, ou pode ser também não-preemptivo?",
		respostas: "O algoritmo precisa ser preemptivo, como veremos a seguir. Como vimos na Aula 6, no algoritmo de escalonamento por round ro- bin, cada processo executa no processador por no máximo um quantum (um intervalo fixo de tempo definido pelo sistema operacional). Após executar por um quantum, o processo somente executará novamente, por mais um quantum, após todos os outros processos no estado pronto executarem também por um quantum. Para garantir o funcionamento do algoritmo, precisamos executar o escalonador em intervalos fixos de tempo (iguais ao quantum), para que ele possa alternar o uso do processador entre os processos no estado pronto. Isso não poderá ser feito se o algoritmo for não-preemptivo porque, neste caso, o escalo- nador somente será executado se o processo atualmente em execução fizer alguma operação de E/S ou terminar a sua execução. Já um al- goritmo preemptivo, além de executar o escalonador nestes casos, o executa também em intervalos fixos de tempo, usando o temporizador do hardware para gerar uma interrupção entre cada um destes interva- los. Logo, para poder alternar o uso do processador entre os processos em intervalos fixos de tempo iguais ao quantum, precisaremos que o algoritmo seja preemptivo.",
	},
	{
		title: "Qual é a diferença entre um sistema operacional estruturado em camadas e um sistema operacional baseado em anéis? Justifique a sua resposta.",
		respostas: "Como vimos na Aula 3, em ambas as estruturações o núcleo do sistema operacional é dividido em diversas camadas organizadas de modo hierárquico, sendo que cada uma destas camadas gerencia uma parte do hardware do computador. Além disso, cada camada oferece, às camadas superiores a ela na hierarquia, uma versão abstrata da parte do hardware mais fácil de ser usada. A diferença está em que em um sistema operacional estruturado em camadas, uma camada não é obri- gada a usar as versões abstratas das partes do hardware gerenciadas pelas camadas inferiores a ela na hierarquia, isto é, ela pode acessar diretamente as partes do hardware. Com isso, a abstração fornecida pela estruturação não é obrigatória e somente serve para organizar o código do núcleo. Já em um sistema operacional baseado em anéis, a estruturação é forçada pelo hardware do computador. Nesta última estruturação, um anel (é assim que uma camada é chamada nesta es- truturação) somente pode acessar as versões abstratas das partes do hardware gerenciadas pelos anéis inferiores da hierarquia. Isto ocorre porque o hardware sempre gera um erro se um anel tenta acessar dire- tamente uma dessas partes do hardware. Logo, a abstração fornecida pela estruturação deve sempre ser respeitada e, portanto, não é somente uma organização para o código do núcleo.",
	},
	{
		title: "Como vimos nas aulas, existem três estados, executando, pronto e bloqueado, em que um processo pode estar em um dado momento. É possı́vel desenvolver um sistema operacional sem um destes estados?",
		respostas: "Sim, é possı́vel desenvolver um sistema operacional sem o es- tado bloqueado. Neste caso, ao invés de suspendermos a execução de um processo quando ele precisar esperar pela ocorrência de um evento externo, podemos simplesmente colocar o processo em espera ocupada. Isto pode ser feito com uma verificação contı́nua da ocorrência do evento e permitindo que o processo somente saia deste laço de veri- ficação quando o evento ocorrer. Em relação aos outros estados, eles sempre são necessários, pois mesmo que o sistema operacioanal não use a multiprogramação e não bloqueie os processos, ainda precisamos suspender a execução dos processos. Isto ocorre quando precisamos tratar os eventos externos prioriotários, como as interrupções geradas pelos dispositivos de E/S, e não existir um processador disponı́vel para executar o código do tratador da interrupção.",
	},
	{
		title: "Descreva como os semáforos podem ser usados para simplificar o tratamento das interrupções dos dispositivos de E/S.",
		respostas: "Os semáforos poderão facilitar o tratamento das interrupções se associarmos, a cada um dos dispositivos de E/S do computador, um semáforo binário, o qual será usado para bloquear o processo que executa o driver deste dispositivo até que o dispositivo gere uma in- terrupção. Quando uma interrupção for gerada pelo dispositivo, uma operação V sobre o semáforo associado ao dispositivo será executada pelo sistema operacional, o que fará com que o seu driver seja des- bloqueado e possa tratar a interrupção. Além disso, ao inicializar e sempre após tratar de uma interrupção, o driver de um dispositivo deverá executar uma operação P sobre o semáforo associado ao dis- positivo. Finalmente, como um dispositivo somente gera interrupções após uma operação de E/S ser inicializada sobre ele, o valor inicial do seu semáforo deverá ser de 0, o que fará com o que o seu driver seja bloqueado ao inicializar até que uma interrupção seja gerada.",
	},
	{
		title: "Descreva o funcionamento do escalonamento de dois nı́veis, enfa- tizando por que o seu uso é necessário.",
		respostas: "Dependendo do número de processos em execução no sistema operacional, nem sempre podemos armazenar todos eles na memória, ou seja, alguns processos devem necessariamente ser armazenados no disco. Porém, como os tempos de comutação dos processos são bem maiores se a comutação é feita diretamente do disco, devido ao tempo de acesso ao disco ser bem maior do que à memória, é inviável usarmos um algoritmo de escalonamento tradicional. O algoritmo de escalo- namento de dois nı́veis, descrito a seguir, foi criado exatamente para resolver este problema. Neste algoritmo, dois escalonadores (e por- tanto dois algoritmos de escalonamento não necessariamente iguais) serão usados: o escalonador de baixo nı́vel e o escalonador de alto nı́vel. O escalonador de baixo nı́vel executa a tarefa do esca- lonador tradicional, isto é, ele é o responsável por escolher, dentre os processos prontos que estão na memória, qual deles é o próximo a ser executado no processador. Já o escalonador de alto nı́vel escolhe qual dos processos do disco deve ser carregado na memória, no lugar de um outro processo, também escolhido, que é então salvo no disco. Note que o tempo de comutação dos processos não depende mais do tempo de acesso ao disco, porque o escalonador de baixo nı́vel somente escolhe um processo dentre os processos que estão na memória.",
	},
	{
		title: "Por que os programas de usuário não podem executar no modo supervisor? O núcleo do sistema operacional pode executar no modo usuário?",
		respostas: "Um programa de usuário não pode executar no modo super- visor porque, neste modo, ele teria acesso direto a todo o hardware do computador. Devido a isso, a integridade dos dispositivos fı́sicos pode- ria ser comprometida, porque cada programa de usuário poderia acessar o mesmo dispositivo de um modo diferente (por exemplo, os dados ar- mazenados em um disco poderiam ser comprometidos). Além disso, também poderı́amos ter problemas de segurança e de consistência du- rante a execução dos programas, porque um programa poderia acessar e/ou alterar os dados usados exclusivamente por um outro programa. Finalmente, um programa poderia executar do seu inı́cio até o seu término, mesmo que o sistema operacional usasse a multiprogramação, porque ele poderia usar exclusivamente o processador. - O núcleo do sistema operacional não pode executar no modo usuário, porque ele precisaria ter acesso direto aos dispositivos fı́sicos para, pelo menos, poder enviar comandos para as suas controladoras (o geren- ciamento dos dispositivos pelo núcleo depende da estrutura na qual o sistema operacional foi baseado). Além disso, o sistema também precisaria gerenciar a memória alocada aos programas, para poder dis- tribuı́-la entre eles, e garantir que um programa não acesse a memória dos outros programas. Finalmente, o sistema precisaria gerenciar a alocação do processador entre os diversos programas em execução.",
	},
	{
		title: "Por que a velocidade de execução de um processo pode ser re- duzida e o tempo de execução das operações de E/S feitas por este processo pode ser aumentado, se o processo estiver executando em um sistema operacional sobre uma máquina virtual? Justifique a sua res- posta.",
		respostas: "A redução da velocidade de execução do processo e o au- mento no tempo de execução das operações de E/S ocorre porque uma máquina virtual é uma simulação da máquina real. Em relação à velo- cidade de execução ser reduzida, isso ocorre porque, como parte da si- mulação, o monitor de máquina virtual deve alternar o uso do processa- dor do hardware entre os processadores virtuais das diversas máquinas virtuais em execução. Além disso, alguns monitores de máquina virtual podem, ao invés de usar, simular o processador (ou seja, o seu modo de operação) e, com isso, existe um overhead adicional no tempo de execução devido a esta simulação. Já em relação à redução da veloci- dade das operações de E/S, isso ocorre porque o monitor de máquina virtual também precisa simular cada operação de E/S. Esta simulação mapeia cada operação de E/S, feita em uma máquina virtual sobre um dispositivo virtual, na operação de E/S correspondente sobre um dispo- sitivo fı́sico. Logo, existe tambeḿ um aumento no tempo de execução de cada operação de E/S, por causa do overhead gerado pelo mapea- mento.",
	},
	{
		title: "Como os pipes podem ser usados para garantir o correto funcio- namento de dois processos que cooperem para executar uma tarefa em comum, se um dos processos sempre depende dos dados gerados pelo outro processo?",
		respostas: "Como vimos nas aulas 2 e 4, os pipes funcionam ligando a saı́da de um processo, no caso o processo que gera os dados, com a entrada de um outro processo, no caso o processo que depende destes dados. Ao ligarmos estes dois processos pelo pipe, quando o processo que gera os dados escrevê-los em sua saı́da, eles serão copiados para o pipe na ordem em que foram escritos. Além disso, quando o processo que depende dos dados ler a sua entrada, os dados serão lidos do pipe na mesma ordem em que foram escritos, pois o pipe mantém a ordem dos dados. A garantia do correto funcionamento dos processos ocorre porque o processo que gera os dados sempre é bloqueado caso tente escrever dados em sua saı́da quando o pipe estiver cheio, e o processo que depende dos dados sempre é bloqueado caso tente ler dados da sua entrada quando o pipe estiver vazio. Note que os processos não precisam se preocupar com a exclusão mútua ao acessar o pipe, porque ele é um tipo especial de arquivo do sistema operacional, para o qual exclusão mútua já é automaticamente garantida.",
	},
	{
		title: "Descreva como os semáforos podem ajudar a garantir a correta execução de um conjunto de processos que cooperem para executar uma tarefa em comum.",
		respostas: "Os semáforos podem ser usados para garantir a exclusão mútua, ou seja, que somente um processo possa acessar, em um dado momento, a sua seção crı́tica, e a sincronização destes processos, ou seja, que cada processo somente possa executar depois que certas condições, depen- dentes dos outros processos, tenham sido satisfeitas. A exclusão mútua é garantida através do uso de um semáforo binário, com valor inicial 1, sobre o qual cada processo deve executar a operação P imediatamente antes de entrar em sua seção crı́tica e executar a operação V imedia- tamente após sair da sua seção crı́tica. Para garantir a sincronização, precisamos usar um ou mais semáforos (binários e/ou de contagem), sendo que os objetivos destes semáforos e as suas inicializações depen- dem das condições que devem ser atendidas para que cada processo possa executar corretamente. Por exemplo, no problema do produ- tor/consumidor precisamos usar dois semáforos de contagem para a sincronização dos processos. O primeiro, inicializado com o tamanho do buffer, é usado para bloquear o processo produtor caso o buffer es- teja cheio. Já o segundo, inicializado com 0, é usado para bloquear o processo consumidor caso o buffer esteja vazio. Note que, neste exem- plo, o processo produtor deve executar a operação P sobre o primeiro semáforo antes de colocar um elemento no buffer, e executar a operação V sobre o segundo após colocar este elemento. Já o processo consumi- dor deve executar a operação P sobre o segundo antes de retirar um elemento do buffer, e executar a operação V sobre o primeiro após re- mover este elemento.",
	},
	{
		title: "Quais são as principais caracterı́sticas de um sistema baseado no modelo cliente-servidor em relação (i) ao tipo de núcleo; (ii) às chama- das ao sistema operacional e (iii) ao gerenciamento do hardware.",
		respostas: "(i) Nos sistemas baseados no modelo cliente-servidor, o núcleo do sistema operacional, chamado de micronúcleo, somente é res- ponsável por duas tarefas: gerenciar a troca de mensagens entre os processos executando no modo usuário; e enviar os comandos às con- troladoras dos dispositivos do hardware dados em mensagens especiais enviadas pelos processos executando no modo usuário. (ii) Neste mo- delo, todo o gerenciamento do sistema operacional é feito por processos especiais em execução no modo usuário, chamados de processos servi- dores. Quando um processo deseja executar uma chamada ao sistema operacional, ele envia uma mensagem ao processo servidor responsável por tratar as chamadas ao sistema operacional. Este processo servidor, após fazer todas as ações necessárias à execução da chamada enviará, também usando uma mensagem, o resultado da chamada ao processo que fez a chamada. (iii) Já em relação ao gerenciamento do hardware, cada processo servidor responsável por um dispositivo do hardware fará todas as tarefas de gerenciamento no modo usuário, com exceção do acesso direto a este dispositivo. Quando o processo servidor precisar enviar comandos à controladora do dispositivo, ele enviará aquela men- sagem especial ao micronúcleo que, por sua vez, repassará os comandos contidos na mensagem à controladora do dispositivo.",
	},
	{
		title: "O que são as seções crı́ticas",
		respostas: "Quando um conjunto de processos cooperam para executar uma tarefa em comum eles, em geral, compartilham os diversos re- cursos necessários à execução daquela tarefa. Se alguns dos recursos compartilhados forem dedicados então, para que a tarefa seja execu- tada corretamente, cada um deles deverá ser acessado exclusivamente por um dos processos em um dado intervalo de tempo. Neste cenário, a seção crı́tica de cada processo é a parte do seu código que acessa recursos dedicados. Note que, devido à necessidade de se acessar ex- clusivamente o recurso, a seção crı́tica de um processo somente deverá ser executada se nenhuma das seções crı́ticas dos outros processos que acessam este mesmo recurso estiverem sendo executadas.",
	},
]